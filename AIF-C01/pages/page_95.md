## Question #95

 Which prompting technique can protect against prompt injection attacks?

- A. Adversarial prompting

- B. Zero-shot prompting

- C. Least-to-most prompting

- D. Chain-of-thought prompting