## Question #29

 A company wants to use a large language model (LLM) to develop a conversational agent. The company needs to prevent the LLM from being manipulated with common prompt engineering techniques to perform undesirable actions or expose sensitive information.

Which action will reduce these risks?

- A. Create a prompt template that teaches the LLM to detect attack patterns.

- B. Increase the temperature parameter on invocation requests to the LLM.

- C. Avoid using LLMs that are not listed in Amazon SageMaker.

- D. Decrease the number of input tokens on invocations of the LLM.