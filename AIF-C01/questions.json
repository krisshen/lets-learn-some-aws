[
  {
    "id": 1,
    "question": "## Question #1\n\nA company makes forecasts each quarter to decide how to optimize operations to meet expected demand. The company uses ML models to make these forecasts.\n\nAn AI practitioner is writing a report about the trained ML models to provide transparency and explainability to company stakeholders.\n\nWhat should the AI practitioner include in the report to meet the transparency and explainability requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Code for model training",
      "B": "Partial dependence plots (PDPs)",
      "C": "Sample data for training",
      "D": "Model convergence tables "
    },
    "answer": "B"
  },
  {
    "id": 2,
    "question": "## Question #2\n\nA law firm wants to build an AI application by using large language models (LLMs). The application will read legal documents and extract key points from the documents.\n\nWhich solution meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Build an automatic named entity recognition system.",
      "B": "Create a recommendation engine.",
      "C": "Develop a summarization chatbot.",
      "D": "Develop a multi-language translation system. "
    },
    "answer": "C"
  },
  {
    "id": 3,
    "question": "## Question #3\n\nA company wants to classify human genes into 20 categories based on gene characteristics. The company needs an ML algorithm to document how the inner mechanism of the model affects the output.\n\nWhich ML algorithm meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Decision trees",
      "B": "Linear regression",
      "C": "Logistic regression",
      "D": "Neural networks "
    },
    "answer": "A"
  },
  {
    "id": 4,
    "question": "## Question #4\n\nA company has built an image classification model to predict plant diseases from photos of plant leaves. The company wants to evaluate how many images the model classified correctly.\n\nWhich evaluation metric should the company use to measure the model's performance?",
    "question_type": "single_select",
    "options": {
      "A": "R-squared score",
      "B": "Accuracy",
      "C": "Root mean squared error (RMSE)",
      "D": "Learning rate "
    },
    "answer": "B"
  },
  {
    "id": 5,
    "question": "## Question #5\n\nA company is using a pre-trained large language model (LLM) to build a chatbot for product recommendations. The company needs the LLM outputs to be short and written in a specific language.\n\nWhich solution will align the LLM response quality with the company's expectations?",
    "question_type": "single_select",
    "options": {
      "A": "Adjust the prompt.",
      "B": "Choose an LLM of a different size.",
      "C": "Increase the temperature.",
      "D": "Increase the Top K value. "
    },
    "answer": "A"
  },
  {
    "id": 6,
    "question": "## Question #6\n\nA company uses Amazon SageMaker for its ML pipeline in a production environment. The company has large input data sizes up to 1 GB and processing times up to 1 hour. The company needs near real-time latency.\n\nWhich SageMaker inference option meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Real-time inference",
      "B": "Serverless inference",
      "C": "Asynchronous inference",
      "D": "Batch transform "
    },
    "answer": "C"
  },
  {
    "id": 7,
    "question": "## Question #7\n\nA company is using domain-specific models. The company wants to avoid creating new models from the beginning. The company instead wants to adapt pre-trained models to create models for new, related tasks.\n\nWhich ML strategy meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Increase the number of epochs.",
      "B": "Use transfer learning.",
      "C": "Decrease the number of epochs.",
      "D": "Use unsupervised learning. "
    },
    "answer": "B"
  },
  {
    "id": 8,
    "question": "## Question #8\n\nA company is building a solution to generate images for protective eyewear. The solution must have high accuracy and must minimize the risk of incorrect annotations.\n\nWhich solution will meet these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Human-in-the-loop validation by using Amazon SageMaker Ground Truth Plus",
      "B": "Data augmentation by using an Amazon Bedrock knowledge base",
      "C": "Image recognition by using Amazon Rekognition",
      "D": "Data summarization by using Amazon QuickSight Q "
    },
    "answer": "A"
  },
  {
    "id": 9,
    "question": "## Question #9\n\nA company wants to create a chatbot by using a foundation model (FM) on Amazon Bedrock. The FM needs to access encrypted data that is stored in an Amazon S3 bucket. The data is encrypted with Amazon S3 managed keys (SSE-S3).\n\nThe FM encounters a failure when attempting to access the S3 bucket data.\n\nWhich solution will meet these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Ensure that the role that Amazon Bedrock assumes has permission to decrypt data with the correct encryption key.",
      "B": "Set the access permissions for the S3 buckets to allow public access to enable access over the internet.",
      "C": "Use prompt engineering techniques to tell the model to look for information in Amazon S3.",
      "D": "Ensure that the S3 data does not contain sensitive information. "
    },
    "answer": "A"
  },
  {
    "id": 10,
    "question": "## Question #10\n\nA company wants to use language models to create an application for inference on edge devices. The inference must have the lowest latency possible.\n\nWhich solution will meet these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Deploy optimized small language models (SLMs) on edge devices.",
      "B": "Deploy optimized large language models (LLMs) on edge devices.",
      "C": "Incorporate a centralized small language model (SLM) API for asynchronous communication with edge devices.",
      "D": "Incorporate a centralized large language model (LLM) API for asynchronous communication with edge devices. "
    },
    "answer": "A"
  },
  {
    "id": 11,
    "question": "## Question #11\n\nA company wants to build an ML model by using Amazon SageMaker. The company needs to share and manage variables for model development across multiple teams.\n\nWhich SageMaker feature meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Amazon SageMaker Feature Store",
      "B": "Amazon SageMaker Data Wrangler",
      "C": "Amazon SageMaker Clarify",
      "D": "Amazon SageMaker Model Cards "
    },
    "answer": "A"
  },
  {
    "id": 12,
    "question": "## Question #12\n\nA company wants to use generative AI to increase developer productivity and software development. The company wants to use Amazon Q Developer.\n\nWhat can Amazon Q Developer do to help the company meet these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Create software snippets, reference tracking, and open source license tracking.",
      "B": "Run an application without provisioning or managing servers.",
      "C": "Enable voice commands for coding and providing natural language search.",
      "D": "Convert audio files to text documents by using ML models. "
    },
    "answer": "A"
  },
  {
    "id": 13,
    "question": "## Question #13\n\nA financial institution is using Amazon Bedrock to develop an AI application. The application is hosted in a VPC. To meet regulatory compliance standards, the VPC is not allowed access to any internet traffic.\n\nWhich AWS service or feature will meet these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "AWS PrivateLink",
      "B": "Amazon Macie",
      "C": "Amazon CloudFront",
      "D": "Internet gateway "
    },
    "answer": "A"
  },
  {
    "id": 14,
    "question": "## Question #14\n\nA company wants to develop an educational game where users answer questions such as the following: \"A jar contains six red, four green, and three yellow marbles. What is the probability of choosing a green marble from the jar?\" Which solution meets these requirements with the LEAST operational overhead?",
    "question_type": "single_select",
    "options": {
      "A": "Use supervised learning to create a regression model that will predict probability.",
      "B": "Use reinforcement learning to train a model to return the probability.",
      "C": "Use code that will calculate probability by using simple rules and computations.",
      "D": "Use unsupervised learning to create a model that will estimate probability density. "
    },
    "answer": "C"
  },
  {
    "id": 15,
    "question": "## Question #15\n\nWhich metric measures the runtime efficiency of operating AI models?",
    "question_type": "single_select",
    "options": {
      "A": "Customer satisfaction score (CSAT)",
      "B": "Training time for each epoch",
      "C": "Average response time",
      "D": "Number of training instances "
    },
    "answer": "C"
  },
  {
    "id": 16,
    "question": "## Question #16\n\nA company is building a contact center application and wants to gain insights from customer conversations. The company wants to analyze and extract key information from the audio of the customer calls.\n\nWhich solution meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Build a conversational chatbot by using Amazon Lex.",
      "B": "Transcribe call recordings by using Amazon Transcribe.",
      "C": "Extract information from call recordings by using Amazon SageMaker Model Monitor.",
      "D": "Create classification labels by using Amazon Comprehend. "
    },
    "answer": "B"
  },
  {
    "id": 17,
    "question": "## Question #17\n\nA company has petabytes of unlabeled customer data to use for an advertisement campaign. The company wants to classify its customers into tiers to advertise and promote the company's products.\n\nWhich methodology should the company use to meet these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Supervised learning",
      "B": "Unsupervised learning",
      "C": "Reinforcement learning",
      "D": "Reinforcement learning from human feedback (RLHF) "
    },
    "answer": "B"
  },
  {
    "id": 18,
    "question": "## Question #18\n\nAn AI practitioner wants to use a foundation model (FM) to design a search application. The search application must handle queries that have text and images.\n\nWhich type of FM should the AI practitioner use to power the search application?",
    "question_type": "single_select",
    "options": {
      "A": "Multi-modal embedding model",
      "B": "Text embedding model",
      "C": "Multi-modal generation model",
      "D": "Image generation model "
    },
    "answer": "A"
  },
  {
    "id": 19,
    "question": "## Question #19\n\nA company uses a foundation model (FM) from Amazon Bedrock for an AI search tool. The company wants to fine-tune the model to be more accurate by using the company's data.\n\nWhich strategy will successfully fine-tune the model?",
    "question_type": "single_select",
    "options": {
      "A": "Provide labeled data with the prompt field and the completion field.",
      "B": "Prepare the training dataset by creating a .txt file that contains multiple lines in .csv format.",
      "C": "Purchase Provisioned Throughput for Amazon Bedrock.",
      "D": "Train the model on journals and textbooks. "
    },
    "answer": "A"
  },
  {
    "id": 20,
    "question": "## Question #20\n\nA company wants to use AI to protect its application from threats. The AI solution needs to check if an IP address is from a suspicious source.\n\nWhich solution meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Build a speech recognition system.",
      "B": "Create a natural language processing (NLP) named entity recognition system.",
      "C": "Develop an anomaly detection system.",
      "D": "Create a fraud forecasting system. "
    },
    "answer": "C"
  },
  {
    "id": 21,
    "question": "## Question #21\n\nWhich feature of Amazon OpenSearch Service gives companies the ability to build vector database applications?",
    "question_type": "single_select",
    "options": {
      "A": "Integration with Amazon S3 for object storage",
      "B": "Support for geospatial indexing and queries",
      "C": "Scalable index management and nearest neighbor search capability",
      "D": "Ability to perform real-time analysis on streaming data "
    },
    "answer": "C"
  },
  {
    "id": 22,
    "question": "## Question #22\n\nWhich option is a use case for generative AI models?",
    "question_type": "single_select",
    "options": {
      "A": "Improving network security by using intrusion detection systems",
      "B": "Creating photorealistic images from text descriptions for digital marketing",
      "C": "Enhancing database performance by using optimized indexing",
      "D": "Analyzing financial data to forecast stock market trends "
    },
    "answer": "B"
  },
  {
    "id": 23,
    "question": "## Question #23\n\nA company wants to build a generative AI application by using Amazon Bedrock and needs to choose a foundation model (FM).\n\nThe company wants to know how much information can fit into one prompt.\n\nWhich consideration will inform the company's decision?",
    "question_type": "single_select",
    "options": {
      "A": "Temperature",
      "B": "Context window",
      "C": "Batch size",
      "D": "Model size "
    },
    "answer": "B"
  },
  {
    "id": 24,
    "question": "## Question #24\n\nA company wants to make a chatbot to help customers. The chatbot will help solve technical problems without human intervention.\n\nThe company chose a foundation model (FM) for the chatbot. The chatbot needs to produce responses that adhere to company tone.\n\nWhich solution meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Set a low limit on the number of tokens the FM can produce.",
      "B": "Use batch inferencing to process detailed responses.",
      "C": "Experiment and refine the prompt until the FM produces the desired responses.",
      "D": "Define a higher number for the temperature parameter. "
    },
    "answer": "C"
  },
  {
    "id": 25,
    "question": "## Question #25\n\nA company wants to use a large language model (LLM) on Amazon Bedrock for sentiment analysis. The company wants to classify the sentiment of text passages as positive or negative.\n\nWhich prompt engineering strategy meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Provide examples of text passages with corresponding positive or negative labels in the prompt followed by the new text passage to be classified.",
      "B": "Provide a detailed explanation of sentiment analysis and how LLMs work in the prompt.",
      "C": "Provide the new text passage to be classified without any additional context or examples.",
      "D": "Provide the new text passage with a few examples of unrelated tasks, such as text summarization or question answering. "
    },
    "answer": "A"
  },
  {
    "id": 26,
    "question": "## Question #26\n\nA security company is using Amazon Bedrock to run foundation models (FMs). The company wants to ensure that only authorized users invoke the models. The company needs to identify any unauthorized access attempts to set appropriate AWS Identity and Access Management (IAM) policies and roles for future iterations of the FMs.\n\nWhich AWS service should the company use to identify unauthorized users that are trying to access Amazon Bedrock?",
    "question_type": "single_select",
    "options": {
      "A": "AWS Audit Manager",
      "B": "AWS CloudTrail",
      "C": "Amazon Fraud Detector",
      "D": "AWS Trusted Advisor "
    },
    "answer": "B"
  },
  {
    "id": 27,
    "question": "## Question #27\n\nA company has developed an ML model for image classification. The company wants to deploy the model to production so that a web application can use the model.\n\nThe company needs to implement a solution to host the model and serve predictions without managing any of the underlying infrastructure.\n\nWhich solution will meet these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Use Amazon SageMaker Serverless Inference to deploy the model.",
      "B": "Use Amazon CloudFront to deploy the model.",
      "C": "Use Amazon API Gateway to host the model and serve predictions.",
      "D": "Use AWS Batch to host the model and serve predictions. "
    },
    "answer": "A"
  },
  {
    "id": 28,
    "question": "## Question #28\n\nAn AI company periodically evaluates its systems and processes with the help of independent software vendors (ISVs). The company needs to receive email message notifications when an ISV's compliance reports become available.\n\nWhich AWS service can the company use to meet this requirement?",
    "question_type": "single_select",
    "options": {
      "A": "AWS Audit Manager",
      "B": "AWS Artifact",
      "C": "AWS Trusted Advisor",
      "D": "AWS Data Exchange "
    },
    "answer": "B"
  },
  {
    "id": 29,
    "question": "## Question #29\n\nA company wants to use a large language model (LLM) to develop a conversational agent. The company needs to prevent the LLM from being manipulated with common prompt engineering techniques to perform undesirable actions or expose sensitive information.\n\nWhich action will reduce these risks?",
    "question_type": "single_select",
    "options": {
      "A": "Create a prompt template that teaches the LLM to detect attack patterns.",
      "B": "Increase the temperature parameter on invocation requests to the LLM.",
      "C": "Avoid using LLMs that are not listed in Amazon SageMaker.",
      "D": "Decrease the number of input tokens on invocations of the LLM. "
    },
    "answer": "A"
  },
  {
    "id": 30,
    "question": "## Question #30\n\nA company is using the Generative AI Security Scoping Matrix to assess security responsibilities for its solutions. The company has identified four different solution scopes based on the matrix.\n\nWhich solution scope gives the company the MOST ownership of security responsibilities?",
    "question_type": "single_select",
    "options": {
      "A": "Using a third-party enterprise application that has embedded generative AI features.",
      "B": "Building an application by using an existing third-party generative AI foundation model (FM).",
      "C": "Refining an existing third-party generative AI foundation model (FM) by fine-tuning the model by using data specific to the business.",
      "D": "Building and training a generative AI model from scratch by using specific data that a customer owns. "
    },
    "answer": "D"
  },
  {
    "id": 31,
    "question": "## Question #31\n\nAn AI practitioner has a database of animal photos. The AI practitioner wants to automatically identify and categorize the animals in the photos without manual human effort.\n\nWhich strategy meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Object detection",
      "B": "Anomaly detection",
      "C": "Named entity recognition",
      "D": "Inpainting "
    },
    "answer": "A"
  },
  {
    "id": 32,
    "question": "## Question #32\n\nA company wants to create an application by using Amazon Bedrock. The company has a limited budget and prefers flexibility without long-term commitment.\n\nWhich Amazon Bedrock pricing model meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "On-Demand",
      "B": "Model customization",
      "C": "Provisioned Throughput",
      "D": "Spot Instance "
    },
    "answer": "A"
  },
  {
    "id": 33,
    "question": "## Question #33\n\nWhich AWS service or feature can help an AI development team quickly deploy and consume a foundation model (FM) within the team's VPC?",
    "question_type": "single_select",
    "options": {
      "A": "Amazon Personalize",
      "B": "Amazon SageMaker JumpStart",
      "C": "PartyRock, an Amazon Bedrock Playground",
      "D": "Amazon SageMaker endpoints "
    },
    "answer": "B"
  },
  {
    "id": 34,
    "question": "## Question #34\n\nHow can companies use large language models (LLMs) securely on Amazon Bedrock?",
    "question_type": "single_select",
    "options": {
      "A": "Design clear and specific prompts. Configure AWS Identity and Access Management (IAM) roles and policies by using least privilege access.",
      "B": "Enable AWS Audit Manager for automatic model evaluation jobs.",
      "C": "Enable Amazon Bedrock automatic model evaluation jobs.",
      "D": "Use Amazon CloudWatch Logs to make models explainable and to monitor for bias. "
    },
    "answer": "A"
  },
  {
    "id": 35,
    "question": "## Question #35\n\nA company has terabytes of data in a database that the company can use for business analysis. The company wants to build an AI-based application that can build a SQL query from input text that employees provide. The employees have minimal experience with technology.\n\nWhich solution meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Generative pre-trained transformers (GPT)",
      "B": "Residual neural network",
      "C": "Support vector machine",
      "D": "WaveNet "
    },
    "answer": "A"
  },
  {
    "id": 36,
    "question": "## Question #36\n\nA company built a deep learning model for object detection and deployed the model to production.\n\nWhich AI process occurs when the model analyzes a new image to identify objects?",
    "question_type": "single_select",
    "options": {
      "A": "Training",
      "B": "Inference",
      "C": "Model deployment",
      "D": "Bias correction "
    },
    "answer": "B"
  },
  {
    "id": 37,
    "question": "## Question #37\n\nAn AI practitioner is building a model to generate images of humans in various professions. The AI practitioner discovered that the input data is biased and that specific attributes affect the image generation and create bias in the model.\n\nWhich technique will solve the problem?",
    "question_type": "single_select",
    "options": {
      "A": "Data augmentation for imbalanced classes",
      "B": "Model monitoring for class distribution",
      "C": "Retrieval Augmented Generation (RAG)",
      "D": "Watermark detection for images "
    },
    "answer": "A"
  },
  {
    "id": 38,
    "question": "## Question #38\n\nA company is implementing the Amazon Titan foundation model (FM) by using Amazon Bedrock. The company needs to supplement the model by using relevant data from the company's private data sources.\n\nWhich solution will meet this requirement?",
    "question_type": "single_select",
    "options": {
      "A": "Use a different FM.",
      "B": "Choose a lower temperature value.",
      "C": "Create an Amazon Bedrock knowledge base.",
      "D": "Enable model invocation logging. "
    },
    "answer": "C"
  },
  {
    "id": 39,
    "question": "## Question #39\n\nA medical company is customizing a foundation model (FM) for diagnostic purposes. The company needs the model to be transparent and explainable to meet regulatory requirements.\n\nWhich solution will meet these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Configure the security and compliance by using Amazon Inspector.",
      "B": "Generate simple metrics, reports, and examples by using Amazon SageMaker Clarify.",
      "C": "Encrypt and secure training data by using Amazon Macie.",
      "D": "Gather more data. Use Amazon Rekognition to add custom labels to the data. "
    },
    "answer": "B"
  },
  {
    "id": 40,
    "question": "## Question #40\n\nA company wants to deploy a conversational chatbot to answer customer questions. The chatbot is based on a fine-tuned Amazon SageMaker JumpStart model. The application must comply with multiple regulatory frameworks.\n\nWhich capabilities can the company show compliance for? (Choose two.)",
    "question_type": "multi_select",
    "options": {
      "A": "Auto scaling inference endpoints",
      "B": "Threat detection",
      "C": "Data protection",
      "D": "Cost optimization",
      "E": "Loosely coupled microservices "
    },
    "answer": "BC"
  },
  {
    "id": 41,
    "question": "## Question #41\n\nA company is training a foundation model (FM). The company wants to increase the accuracy of the model up to a specific acceptance level.\n\nWhich solution will meet these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Decrease the batch size.",
      "B": "Increase the epochs.",
      "C": "Decrease the epochs.",
      "D": "Increase the temperature parameter. "
    },
    "answer": "B"
  },
  {
    "id": 42,
    "question": "## Question #42\n\nA company is building a large language model (LLM) question answering chatbot. The company wants to decrease the number of actions call center employees need to take to respond to customer questions.\n\nWhich business objective should the company use to evaluate the effect of the LLM chatbot?",
    "question_type": "single_select",
    "options": {
      "A": "Website engagement rate",
      "B": "Average call duration",
      "C": "Corporate social responsibility",
      "D": "Regulatory compliance "
    },
    "answer": "B"
  },
  {
    "id": 43,
    "question": "## Question #43\n\nWhich functionality does Amazon SageMaker Clarify provide?",
    "question_type": "single_select",
    "options": {
      "A": "Integrates a Retrieval Augmented Generation (RAG) workflow",
      "B": "Monitors the quality of ML models in production",
      "C": "Documents critical details about ML models",
      "D": "Identifies potential bias during data preparation "
    },
    "answer": "D"
  },
  {
    "id": 44,
    "question": "## Question #44\n\nA company is developing a new model to predict the prices of specific items. The model performed well on the training dataset. When the company deployed the model to production, the model's performance decreased significantly.\n\nWhat should the company do to mitigate this problem?",
    "question_type": "single_select",
    "options": {
      "A": "Reduce the volume of data that is used in training.",
      "B": "Add hyperparameters to the model.",
      "C": "Increase the volume of data that is used in training.",
      "D": "Increase the model training time. "
    },
    "answer": "C"
  },
  {
    "id": 45,
    "question": "## Question #45\n\nAn ecommerce company wants to build a solution to determine customer sentiments based on written customer reviews of products.\n\nWhich AWS services meet these requirements? (Choose two.)",
    "question_type": "multi_select",
    "options": {
      "A": "Amazon Lex",
      "B": "Amazon Comprehend",
      "C": "Amazon Polly",
      "D": "Amazon Bedrock",
      "E": "Amazon Rekognition "
    },
    "answer": "BD"
  },
  {
    "id": 46,
    "question": "## Question #46\n\nA company wants to use large language models (LLMs) with Amazon Bedrock to develop a chat interface for the company's product manuals. The manuals are stored as PDF files.\n\nWhich solution meets these requirements MOST cost-effectively?",
    "question_type": "single_select",
    "options": {
      "A": "Use prompt engineering to add one PDF file as context to the user prompt when the prompt is submitted to Amazon Bedrock.",
      "B": "Use prompt engineering to add all the PDF files as context to the user prompt when the prompt is submitted to Amazon Bedrock.",
      "C": "Use all the PDF documents to fine-tune a model with Amazon Bedrock. Use the fine-tuned model to process user prompts.",
      "D": "Upload PDF documents to an Amazon Bedrock knowledge base. Use the knowledge base to provide context when users submit prompts to Amazon Bedrock. "
    },
    "answer": "D"
  },
  {
    "id": 47,
    "question": "## Question #47\n\nA social media company wants to use a large language model (LLM) for content moderation. The company wants to evaluate the LLM outputs for bias and potential discrimination against specific groups or individuals.\n\nWhich data source should the company use to evaluate the LLM outputs with the LEAST administrative effort?",
    "question_type": "single_select",
    "options": {
      "A": "User-generated content",
      "B": "Moderation logs",
      "C": "Content moderation guidelines",
      "D": "Benchmark datasets "
    },
    "answer": "D"
  },
  {
    "id": 48,
    "question": "## Question #48\n\nA company wants to use a pre-trained generative AI model to generate content for its marketing campaigns. The company needs to ensure that the generated content aligns with the company's brand voice and messaging requirements.\n\nWhich solution meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Optimize the model's architecture and hyperparameters to improve the model's overall performance.",
      "B": "Increase the model's complexity by adding more layers to the model's architecture.",
      "C": "Create effective prompts that provide clear instructions and context to guide the model's generation.",
      "D": "Select a large, diverse dataset to pre-train a new generative model. "
    },
    "answer": "C"
  },
  {
    "id": 49,
    "question": "## Question #49\n\nA loan company is building a generative AI-based solution to offer new applicants discounts based on specific business criteria. The company wants to build and use an AI model responsibly to minimize bias that could negatively affect some customers.\n\nWhich actions should the company take to meet these requirements? (Choose two.)",
    "question_type": "multi_select",
    "options": {
      "A": "Detect imbalances or disparities in the data.",
      "B": "Ensure that the model runs frequently.",
      "C": "Evaluate the model's behavior so that the company can provide transparency to stakeholders.",
      "D": "Use the Recall-Oriented Understudy for Gisting Evaluation (ROUGE) technique to ensure that the model is 100% accurate.",
      "E": "Ensure that the model's inference time is within the accepted limits. "
    },
    "answer": "AC"
  },
  {
    "id": 50,
    "question": "## Question #50\n\nA company is using an Amazon Bedrock base model to summarize documents for an internal use case. The company trained a custom model to improve the summarization quality.\n\nWhich action must the company take to use the custom model through Amazon Bedrock?",
    "question_type": "single_select",
    "options": {
      "A": "Purchase Provisioned Throughput for the custom model.",
      "B": "Deploy the custom model in an Amazon SageMaker endpoint for real-time inference.",
      "C": "Register the model with the Amazon SageMaker Model Registry.",
      "D": "Grant access to the custom model in Amazon Bedrock. "
    },
    "answer": "A"
  },
  {
    "id": 51,
    "question": "## Question #51\n\nA company needs to choose a model from Amazon Bedrock to use internally. The company must identify a model that generates responses in a style that the company's employees prefer.\n\nWhat should the company do to meet these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Evaluate the models by using built-in prompt datasets.",
      "B": "Evaluate the models by using a human workforce and custom prompt datasets.",
      "C": "Use public model leaderboards to identify the model.",
      "D": "Use the model InvocationLatency runtime metrics in Amazon CloudWatch when trying models. "
    },
    "answer": "B"
  },
  {
    "id": 52,
    "question": "## Question #52\n\nA student at a university is copying content from generative AI to write essays.\n\nWhich challenge of responsible generative AI does this scenario represent?",
    "question_type": "single_select",
    "options": {
      "A": "Toxicity",
      "B": "Hallucinations",
      "C": "Plagiarism",
      "D": "Privacy "
    },
    "answer": "C"
  },
  {
    "id": 53,
    "question": "## Question #53\n\nA company needs to build its own large language model (LLM) based on only the company's private data. The company is concerned about the environmental effect of the training process.\n\nWhich Amazon EC2 instance type has the LEAST environmental effect when training LLMs?",
    "question_type": "single_select",
    "options": {
      "A": "Amazon EC2 C series",
      "B": "Amazon EC2 G series",
      "C": "Amazon EC2 P series",
      "D": "Amazon EC2 Trn series "
    },
    "answer": "D"
  },
  {
    "id": 54,
    "question": "## Question #54\n\nA company wants to build an interactive application for children that generates new stories based on classic stories. The company wants to use Amazon Bedrock and needs to ensure that the results and topics are appropriate for children.\n\nWhich AWS service or feature will meet these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Amazon Rekognition",
      "B": "Amazon Bedrock playgrounds",
      "C": "Guardrails for Amazon Bedrock",
      "D": "Agents for Amazon Bedrock "
    },
    "answer": "C"
  },
  {
    "id": 55,
    "question": "## Question #55\n\nA company is building an application that needs to generate synthetic data that is based on existing data.\n\nWhich type of model can the company use to meet this requirement?",
    "question_type": "single_select",
    "options": {
      "A": "Generative adversarial network (GAN)",
      "B": "XGBoost",
      "C": "Residual neural network",
      "D": "WaveNet "
    },
    "answer": "A"
  },
  {
    "id": 56,
    "question": "## Question #56\n\nA digital devices company wants to predict customer demand for memory hardware. The company does not have coding experience or knowledge of ML algorithms and needs to develop a data-driven predictive model. The company needs to perform analysis on internal data and external data.\n\nWhich solution will meet these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Store the data in Amazon S3. Create ML models and demand forecast predictions by using Amazon SageMaker built-in algorithms that use the data from Amazon S3.",
      "B": "Import the data into Amazon SageMaker Data Wrangler. Create ML models and demand forecast predictions by using SageMaker built-in algorithms.",
      "C": "Import the data into Amazon SageMaker Data Wrangler. Build ML models and demand forecast predictions by using an Amazon Personalize Trending-Now recipe.",
      "D": "Import the data into Amazon SageMaker Canvas. Build ML models and demand forecast predictions by selecting the values in the data from SageMaker Canvas. "
    },
    "answer": "D"
  },
  {
    "id": 57,
    "question": "## Question #57\n\nA company has installed a security camera. The company uses an ML model to evaluate the security camera footage for potential thefts. The company has discovered that the model disproportionately flags people who are members of a specific ethnic group.\n\nWhich type of bias is affecting the model output?",
    "question_type": "single_select",
    "options": {
      "A": "Measurement bias",
      "B": "Sampling bias",
      "C": "Observer bias",
      "D": "Confirmation bias "
    },
    "answer": "B"
  },
  {
    "id": 58,
    "question": "## Question #58\n\nA company is building a customer service chatbot. The company wants the chatbot to improve its responses by learning from past interactions and online resources.\n\nWhich AI learning strategy provides this self-improvement capability?",
    "question_type": "single_select",
    "options": {
      "A": "Supervised learning with a manually curated dataset of good responses and bad responses",
      "B": "Reinforcement learning with rewards for positive customer feedback",
      "C": "Unsupervised learning to find clusters of similar customer inquiries",
      "D": "Supervised learning with a continuously updated FAQ database "
    },
    "answer": "B"
  },
  {
    "id": 59,
    "question": "## Question #59\n\nAn AI practitioner has built a deep learning model to classify the types of materials in images. The AI practitioner now wants to measure the model performance.\n\nWhich metric will help the AI practitioner evaluate the performance of the model?",
    "question_type": "single_select",
    "options": {
      "A": "Confusion matrix",
      "B": "Correlation matrix",
      "C": "R2 score",
      "D": "Mean squared error (MSE) "
    },
    "answer": "A"
  },
  {
    "id": 60,
    "question": "## Question #60\n\nA company has built a chatbot that can respond to natural language questions with images. The company wants to ensure that the chatbot does not return inappropriate or unwanted images.\n\nWhich solution will meet these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Implement moderation APIs.",
      "B": "Retrain the model with a general public dataset.",
      "C": "Perform model validation.",
      "D": "Automate user feedback integration. "
    },
    "answer": "A"
  },
  {
    "id": 61,
    "question": "## Question #61\n\nAn AI practitioner is using an Amazon Bedrock base model to summarize session chats from the customer service department.\n\nThe AI practitioner wants to store invocation logs to monitor model input and output data.\n\nWhich strategy should the AI practitioner use?",
    "question_type": "single_select",
    "options": {
      "A": "Configure AWS CloudTrail as the logs destination for the model.",
      "B": "Enable invocation logging in Amazon Bedrock.",
      "C": "Configure AWS Audit Manager as the logs destination for the model.",
      "D": "Configure model invocation logging in Amazon EventBridge. "
    },
    "answer": "B"
  },
  {
    "id": 62,
    "question": "## Question #62\n\nA company is building an ML model to analyze archived data. The company must perform inference on large datasets that are multiple GBs in size. The company does not need to access the model predictions immediately.\n\nWhich Amazon SageMaker inference option will meet these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Batch transform",
      "B": "Real-time inference",
      "C": "Serverless inference",
      "D": "Asynchronous inference "
    },
    "answer": "A"
  },
  {
    "id": 63,
    "question": "## Question #63\n\nWhich term describes the numerical representations of real-world objects and concepts that AI and natural language processing (NLP) models use to improve understanding of textual information?",
    "question_type": "single_select",
    "options": {
      "A": "Embeddings",
      "B": "Tokens",
      "C": "Models",
      "D": "Binaries "
    },
    "answer": "A"
  },
  {
    "id": 64,
    "question": "## Question #64\n\nA research company implemented a chatbot by using a foundation model (FM) from Amazon Bedrock. The chatbot searches for answers to questions from a large database of research papers.\n\nAfter multiple prompt engineering attempts, the company notices that the FM is performing poorly because of the complex scientific terms in the research papers.\n\nHow can the company improve the performance of the chatbot?",
    "question_type": "single_select",
    "options": {
      "A": "Use few-shot prompting to define how the FM can answer the questions.",
      "B": "Use domain adaptation fine-tuning to adapt the FM to complex scientific terms.",
      "C": "Change the FM inference parameters.",
      "D": "Clean the research paper data to remove complex scientific terms. "
    },
    "answer": "B"
  },
  {
    "id": 65,
    "question": "## Question #65\n\nA company wants to use a large language model (LLM) on Amazon Bedrock for sentiment analysis. The company needs the LLM to produce more consistent responses to the same input prompt.\n\nWhich adjustment to an inference parameter should the company make to meet these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Decrease the temperature value.",
      "B": "Increase the temperature value.",
      "C": "Decrease the length of output tokens.",
      "D": "Increase the maximum generation length. "
    },
    "answer": "A"
  },
  {
    "id": 66,
    "question": "## Question #66\n\nA company wants to develop a large language model (LLM) application by using Amazon Bedrock and customer data that is uploaded to Amazon S3. The company's security policy states that each team can access data for only the team's own customers.\n\nWhich solution will meet these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Create an Amazon Bedrock custom service role for each team that has access to only the team's customer data.",
      "B": "Create a custom service role that has Amazon S3 access. Ask teams to specify the customer name on each Amazon Bedrock request.",
      "C": "Redact personal data in Amazon S3. Update the S3 bucket policy to allow team access to customer data.",
      "D": "Create one Amazon Bedrock role that has full Amazon S3 access. Create IAM roles for each team that have access to only each team's customer folders. "
    },
    "answer": "A"
  },
  {
    "id": 67,
    "question": "## Question #67\n\nA medical company deployed a disease detection model on Amazon Bedrock. To comply with privacy policies, the company wants to prevent the model from including personal patient information in its responses. The company also wants to receive notification when policy violations occur.\n\nWhich solution meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Use Amazon Macie to scan the model's output for sensitive data and set up alerts for potential violations.",
      "B": "Configure AWS CloudTrail to monitor the model's responses and create alerts for any detected personal information.",
      "C": "Use Guardrails for Amazon Bedrock to filter content. Set up Amazon CloudWatch alarms for notification of policy violations.",
      "D": "Implement Amazon SageMaker Model Monitor to detect data drift and receive alerts when model quality degrades. "
    },
    "answer": "C"
  },
  {
    "id": 68,
    "question": "## Question #68\n\nA company manually reviews all submitted resumes in PDF format. As the company grows, the company expects the volume of resumes to exceed the company's review capacity. The company needs an automated system to convert the PDF resumes into plain text format for additional processing.\n\nWhich AWS service meets this requirement?",
    "question_type": "single_select",
    "options": {
      "A": "Amazon Textract",
      "B": "Amazon Personalize",
      "C": "Amazon Lex",
      "D": "Amazon Transcribe "
    },
    "answer": "A"
  },
  {
    "id": 69,
    "question": "## Question #69\n\nAn education provider is building a question and answer application that uses a generative AI model to explain complex concepts. The education provider wants to automatically change the style of the model response depending on who is asking the question. The education provider will give the model the age range of the user who has asked the question.\n\nWhich solution meets these requirements with the LEAST implementation effort?",
    "question_type": "single_select",
    "options": {
      "A": "Fine-tune the model by using additional training data that is representative of the various age ranges that the application will support.",
      "B": "Add a role description to the prompt context that instructs the model of the age range that the response should target.",
      "C": "Use chain-of-thought reasoning to deduce the correct style and complexity for a response suitable for that user.",
      "D": "Summarize the response text depending on the age of the user so that younger users receive shorter responses. "
    },
    "answer": "B"
  },
  {
    "id": 70,
    "question": "## Question #70\n\nWhich strategy evaluates the accuracy of a foundation model (FM) that is used in image classification tasks?",
    "question_type": "single_select",
    "options": {
      "A": "Calculate the total cost of resources used by the model.",
      "B": "Measure the model's accuracy against a predefined benchmark dataset.",
      "C": "Count the number of layers in the neural network.",
      "D": "Assess the color accuracy of images processed by the model. "
    },
    "answer": "B"
  },
  {
    "id": 71,
    "question": "## Question #71\n\nAn accounting firm wants to implement a large language model (LLM) to automate document processing. The firm must proceed responsibly to avoid potential harms.\n\nWhat should the firm do when developing and deploying the LLM? (Choose two.)",
    "question_type": "multi_select",
    "options": {
      "A": "Include fairness metrics for model evaluation.",
      "B": "Adjust the temperature parameter of the model.",
      "C": "Modify the training data to mitigate bias.",
      "D": "Avoid overfitting on the training data.",
      "E": "Apply prompt engineering techniques. "
    },
    "answer": "AC"
  },
  {
    "id": 72,
    "question": "## Question #72\n\nA company is building an ML model. The company collected new data and analyzed the data by creating a correlation matrix, calculating statistics, and visualizing the data.\n\nWhich stage of the ML pipeline is the company currently in?",
    "question_type": "single_select",
    "options": {
      "A": "Data pre-processing",
      "B": "Feature engineering",
      "C": "Exploratory data analysis",
      "D": "Hyperparameter tuning "
    },
    "answer": "C"
  },
  {
    "id": 73,
    "question": "## Question #73\n\nA company has documents that are missing some words because of a database error. The company wants to build an ML model that can suggest potential words to fill in the missing text.\n\nWhich type of model meets this requirement?",
    "question_type": "single_select",
    "options": {
      "A": "Topic modeling",
      "B": "Clustering models",
      "C": "Prescriptive ML models",
      "D": "BERT-based models "
    },
    "answer": "D"
  },
  {
    "id": 74,
    "question": "## Question #74\n\nA company wants to display the total sales for its top-selling products across various retail locations in the past 12 months.\n\nWhich AWS solution should the company use to automate the generation of graphs?",
    "question_type": "single_select",
    "options": {
      "A": "Amazon Q in Amazon EC2",
      "B": "Amazon Q Developer",
      "C": "Amazon Q in Amazon QuickSight",
      "D": "Amazon Q in AWS Chatbot "
    },
    "answer": "C"
  },
  {
    "id": 75,
    "question": "## Question #75\n\nA company is building a chatbot to improve user experience. The company is using a large language model (LLM) from Amazon Bedrock for intent detection. The company wants to use few-shot learning to improve intent detection accuracy.\n\nWhich additional data does the company need to meet these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Pairs of chatbot responses and correct user intents",
      "B": "Pairs of user messages and correct chatbot responses",
      "C": "Pairs of user messages and correct user intents",
      "D": "Pairs of user intents and correct chatbot responses "
    },
    "answer": "C"
  },
  {
    "id": 76,
    "question": "## Question #76\n\nA company is using few-shot prompting on a base model that is hosted on Amazon Bedrock. The model currently uses 10 examples in the prompt. The model is invoked once daily and is performing well. The company wants to lower the monthly cost.\n\nWhich solution will meet these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Customize the model by using fine-tuning.",
      "B": "Decrease the number of tokens in the prompt.",
      "C": "Increase the number of tokens in the prompt.",
      "D": "Use Provisioned Throughput. "
    },
    "answer": "B"
  },
  {
    "id": 77,
    "question": "## Question #77\n\nAn AI practitioner is using a large language model (LLM) to create content for marketing campaigns. The generated content sounds plausible and factual but is incorrect.\n\nWhich problem is the LLM having?",
    "question_type": "single_select",
    "options": {
      "A": "Data leakage",
      "B": "Hallucination",
      "C": "Overfitting",
      "D": "Underfitting "
    },
    "answer": "B"
  },
  {
    "id": 78,
    "question": "## Question #78\n\nAn AI practitioner trained a custom model on Amazon Bedrock by using a training dataset that contains confidential data. The AI practitioner wants to ensure that the custom model does not generate inference responses based on confidential data.\n\nHow should the AI practitioner prevent responses based on confidential data?",
    "question_type": "single_select",
    "options": {
      "A": "Delete the custom model. Remove the confidential data from the training dataset. Retrain the custom model.",
      "B": "Mask the confidential data in the inference responses by using dynamic data masking.",
      "C": "Encrypt the confidential data in the inference responses by using Amazon SageMaker.",
      "D": "Encrypt the confidential data in the custom model by using AWS Key Management Service (AWS KMS). "
    },
    "answer": "A"
  },
  {
    "id": 79,
    "question": "## Question #79\n\nA company has built a solution by using generative AI. The solution uses large language models (LLMs) to translate training manuals from English into other languages. The company wants to evaluate the accuracy of the solution by examining the text generated for the manuals.\n\nWhich model evaluation strategy meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Bilingual Evaluation Understudy (BLEU)",
      "B": "Root mean squared error (RMSE)",
      "C": "Recall-Oriented Understudy for Gisting Evaluation (ROUGE)",
      "D": "F1 score "
    },
    "answer": "A"
  },
  {
    "id": 80,
    "question": "## Question #80\n\nA large retailer receives thousands of customer support inquiries about products every day. The customer support inquiries need to be processed and responded to quickly. The company wants to implement Agents for Amazon Bedrock.\n\nWhat are the key benefits of using Amazon Bedrock agents that could help this retailer?",
    "question_type": "single_select",
    "options": {
      "A": "Generation of custom foundation models (FMs) to predict customer needs",
      "B": "Automation of repetitive tasks and orchestration of complex workflows",
      "C": "Automatically calling multiple foundation models (FMs) and consolidating the results",
      "D": "Selecting the foundation model (FM) based on predefined criteria and metrics "
    },
    "answer": "B"
  },
  {
    "id": 81,
    "question": "## Question #81\n\nWhich option is a benefit of ongoing pre-training when fine-tuning a foundation model (FM)?",
    "question_type": "single_select",
    "options": {
      "A": "Helps decrease the model's complexity",
      "B": "Improves model performance over time",
      "C": "Decreases the training time requirement",
      "D": "Optimizes model inference time "
    },
    "answer": "B"
  },
  {
    "id": 82,
    "question": "## Question #82\n\nWhat are tokens in the context of generative AI models?",
    "question_type": "single_select",
    "options": {
      "A": "Tokens are the basic units of input and output that a generative AI model operates on, representing words, subwords, or other linguistic units.",
      "B": "Tokens are the mathematical representations of words or concepts used in generative AI models.",
      "C": "Tokens are the pre-trained weights of a generative AI model that are fine-tuned for specific tasks.",
      "D": "Tokens are the specific prompts or instructions given to a generative AI model to generate output. "
    },
    "answer": "A"
  },
  {
    "id": 83,
    "question": "## Question #83\n\nA company wants to assess the costs that are associated with using a large language model (LLM) to generate inferences. The company wants to use Amazon Bedrock to build generative AI applications.\n\nWhich factor will drive the inference costs?",
    "question_type": "single_select",
    "options": {
      "A": "Number of tokens consumed",
      "B": "Temperature value",
      "C": "Amount of data used to train the LLM",
      "D": "Total training time "
    },
    "answer": "A"
  },
  {
    "id": 84,
    "question": "## Question #84\n\nA company is using Amazon SageMaker Studio notebooks to build and train ML models. The company stores the data in an Amazon S3 bucket. The company needs to manage the flow of data from Amazon S3 to SageMaker Studio notebooks.\n\nWhich solution will meet this requirement?",
    "question_type": "single_select",
    "options": {
      "A": "Use Amazon Inspector to monitor SageMaker Studio.",
      "B": "Use Amazon Macie to monitor SageMaker Studio.",
      "C": "Configure SageMaker to use a VPC with an S3 endpoint.",
      "D": "Configure SageMaker to use S3 Glacier Deep Archive. "
    },
    "answer": "C"
  },
  {
    "id": 85,
    "question": "## Question #85\n\nA company has a foundation model (FM) that was customized by using Amazon Bedrock to answer customer queries about products. The company wants to validate the model's responses to new types of queries. The company needs to upload a new dataset that Amazon Bedrock can use for validation.\n\nWhich AWS service meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Amazon S3",
      "B": "Amazon Elastic Block Store (Amazon EBS)",
      "C": "Amazon Elastic File System (Amazon EFS)",
      "D": "AWS Snowcone "
    },
    "answer": "A"
  },
  {
    "id": 86,
    "question": "## Question #86\n\nWhich prompting attack directly exposes the configured behavior of a large language model (LLM)?",
    "question_type": "single_select",
    "options": {
      "A": "Prompted persona switches",
      "B": "Exploiting friendliness and trust",
      "C": "Ignoring the prompt template",
      "D": "Extracting the prompt template "
    },
    "answer": "D"
  },
  {
    "id": 87,
    "question": "## Question #87\n\nA company wants to use Amazon Bedrock. The company needs to review which security aspects the company is responsible for when using Amazon Bedrock.\n\nWhich security aspect will the company be responsible for?",
    "question_type": "single_select",
    "options": {
      "A": "Patching and updating the versions of Amazon Bedrock",
      "B": "Protecting the infrastructure that hosts Amazon Bedrock",
      "C": "Securing the company's data in transit and at rest",
      "D": "Provisioning Amazon Bedrock within the company network "
    },
    "answer": "C"
  },
  {
    "id": 88,
    "question": "## Question #88\n\nA social media company wants to use a large language model (LLM) to summarize messages. The company has chosen a few LLMs that are available on Amazon SageMaker JumpStart. The company wants to compare the generated output toxicity of these models.\n\nWhich strategy gives the company the ability to evaluate the LLMs with the LEAST operational overhead?",
    "question_type": "single_select",
    "options": {
      "A": "Crowd-sourced evaluation",
      "B": "Automatic model evaluation",
      "C": "Model evaluation with human workers",
      "D": "Reinforcement learning from human feedback (RLHF) "
    },
    "answer": "B"
  },
  {
    "id": 89,
    "question": "## Question #89\n\nA company is testing the security of a foundation model (FM). During testing, the company wants to get around the safety features and make harmful content.\n\nWhich security technique is this an example of?",
    "question_type": "single_select",
    "options": {
      "A": "Fuzzing training data to find vulnerabilities",
      "B": "Denial of service (DoS)",
      "C": "Penetration testing with authorization",
      "D": "Jailbreak "
    },
    "answer": "D"
  },
  {
    "id": 90,
    "question": "## Question #90\n\nA company needs to use Amazon SageMaker for model training and inference. The company must comply with regulatory requirements to run SageMaker jobs in an isolated environment without internet access.\n\nWhich solution will meet these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Run SageMaker training and inference by using SageMaker Experiments.",
      "B": "Run SageMaker training and Inference by using network Isolation.",
      "C": "Encrypt the data at rest by using encryption for SageMaker geospatial capabilities.",
      "D": "Associate appropriate AWS Identity and Access Management (IAM) roles with the SageMaker jobs. "
    },
    "answer": "B"
  },
  {
    "id": 91,
    "question": "## Question #91\n\nAn ML research team develops custom ML models. The model artifacts are shared with other teams for integration into products and services. The ML team retains the model training code and data. The ML team wants to build a mechanism that the ML team can use to audit models.\n\nWhich solution should the ML team use when publishing the custom ML models?",
    "question_type": "single_select",
    "options": {
      "A": "Create documents with the relevant information. Store the documents in Amazon S3.",
      "B": "Use AWS AI Service Cards for transparency and understanding models.",
      "C": "Create Amazon SageMaker Model Cards with intended uses and training and inference details.",
      "D": "Create model training scripts. Commit the model training scripts to a Git repository. "
    },
    "answer": "C"
  },
  {
    "id": 92,
    "question": "## Question #92\n\nA software company builds tools for customers. The company wants to use AI to increase software development productivity.\n\nWhich solution will meet these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Use a binary classification model to generate code reviews.",
      "B": "Install code recommendation software in the company's developer tools.",
      "C": "Install a code forecasting tool to predict potential code issues.",
      "D": "Use a natural language processing (NLP) tool to generate code. "
    },
    "answer": "B"
  },
  {
    "id": 93,
    "question": "## Question #93\n\nA retail store wants to predict the demand for a specific product for the next few weeks by using the Amazon SageMaker DeepAR forecasting algorithm.\n\nWhich type of data will meet this requirement?",
    "question_type": "single_select",
    "options": {
      "A": "Text data",
      "B": "Image data",
      "C": "Time series data",
      "D": "Binary data "
    },
    "answer": "C"
  },
  {
    "id": 94,
    "question": "## Question #94\n\nA large retail bank wants to develop an ML system to help the risk management team decide on loan allocations for different demographics.\n\nWhat must the bank do to develop an unbiased ML model?",
    "question_type": "single_select",
    "options": {
      "A": "Reduce the size of the training dataset.",
      "B": "Ensure that the ML model predictions are consistent with historical results.",
      "C": "Create a different ML model for each demographic group.",
      "D": "Measure class imbalance on the training dataset. Adapt the training process accordingly. "
    },
    "answer": "D"
  },
  {
    "id": 95,
    "question": "## Question #95\n\nWhich prompting technique can protect against prompt injection attacks?",
    "question_type": "single_select",
    "options": {
      "A": "Adversarial prompting",
      "B": "Zero-shot prompting",
      "C": "Least-to-most prompting",
      "D": "Chain-of-thought prompting "
    },
    "answer": "A"
  },
  {
    "id": 96,
    "question": "## Question #96\n\nA company has fine-tuned a large language model (LLM) to answer questions for a help desk. The company wants to determine if the fine-tuning has enhanced the model's accuracy.\n\nWhich metric should the company use for the evaluation?",
    "question_type": "single_select",
    "options": {
      "A": "Precision",
      "B": "Time to first token",
      "C": "F1 score",
      "D": "Word error rate "
    },
    "answer": "C"
  },
  {
    "id": 97,
    "question": "## Question #97\n\nA company is using Retrieval Augmented Generation (RAG) with Amazon Bedrock and Stable Diffusion to generate product images based on text descriptions. The results are often random and lack specific details. The company wants to increase the specificity of the generated images.\n\nWhich solution meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Increase the number of generation steps.",
      "B": "Use the MASK_IMAGE_BLACK mask source option.",
      "C": "Increase the classifier-free guidance (CFG) scale.",
      "D": "Increase the prompt strength. "
    },
    "answer": "C"
  },
  {
    "id": 98,
    "question": "## Question #98\n\nA company wants to implement a large language model (LLM) based chatbot to provide customer service agents with real-time contextual responses to customers' inquiries. The company will use the company's policies as the knowledge base.\n\nWhich solution will meet these requirements MOST cost-effectively?",
    "question_type": "single_select",
    "options": {
      "A": "Retrain the LLM on the company policy data.",
      "B": "Fine-tune the LLM on the company policy data.",
      "C": "Implement Retrieval Augmented Generation (RAG) for in-context responses.",
      "D": "Use pre-training and data augmentation on the company policy data. "
    },
    "answer": "C"
  },
  {
    "id": 99,
    "question": "## Question #99\n\nA company wants to create a new solution by using AWS Glue. The company has minimal programming experience with AWS Glue.\n\nWhich AWS service can help the company use AWS Glue?",
    "question_type": "single_select",
    "options": {
      "A": "Amazon Q Developer",
      "B": "AWS Config",
      "C": "Amazon Personalize",
      "D": "Amazon Comprehend "
    },
    "answer": "A"
  },
  {
    "id": 100,
    "question": "## Question #100\n\nA company is developing a mobile ML app that uses a phone's camera to diagnose and treat insect bites. The company wants to train an image classification model by using a diverse dataset of insect bite photos from different genders, ethnicities, and geographic locations around the world.\n\nWhich principle of responsible AI does the company demonstrate in this scenario?",
    "question_type": "single_select",
    "options": {
      "A": "Fairness",
      "B": "Explainability",
      "C": "Governance",
      "D": "Transparency "
    },
    "answer": "A"
  },
  {
    "id": 101,
    "question": "## Question #101\n\nA company is developing an ML model to make loan approvals. The company must implement a solution to detect bias in the model. The company must also be able to explain the model's predictions.\n\nWhich solution will meet these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Amazon SageMaker Clarify",
      "B": "Amazon SageMaker Data Wrangler",
      "C": "Amazon SageMaker Model Cards",
      "D": "AWS AI Service Cards "
    },
    "answer": "A"
  },
  {
    "id": 102,
    "question": "## Question #102\n\nA company has developed a generative text summarization model by using Amazon Bedrock. The company will use Amazon Bedrock automatic model evaluation capabilities.\n\nWhich metric should the company use to evaluate the accuracy of the model?",
    "question_type": "single_select",
    "options": {
      "A": "Area Under the ROC Curve (AUC) score",
      "B": "F1 score",
      "C": "BERTScore",
      "D": "Real world knowledge (RWK) score "
    },
    "answer": "C"
  },
  {
    "id": 103,
    "question": "## Question #103\n\nAn AI practitioner wants to predict the classification of flowers based on petal length, petal width, sepal length, and sepal width.\n\nWhich algorithm meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "K-nearest neighbors (k-NN)",
      "B": "K-mean",
      "C": "Autoregressive Integrated Moving Average (ARIMA)",
      "D": "Linear regression "
    },
    "answer": "A"
  },
  {
    "id": 104,
    "question": "## Question #104\n\nA company is using custom models in Amazon Bedrock for a generative AI application. The company wants to use a company managed encryption key to encrypt the model artifacts that the model customization jobs create.\n\nWhich AWS service meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "AWS Key Management Service (AWS KMS)",
      "B": "Amazon Inspector",
      "C": "Amazon Macie",
      "D": "AWS Secrets Manager "
    },
    "answer": "A"
  },
  {
    "id": 105,
    "question": "## Question #105\n\nA company wants to use large language models (LLMs) to produce code from natural language code comments.\n\nWhich LLM feature meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Text summarization",
      "B": "Text generation",
      "C": "Text completion",
      "D": "Text classification "
    },
    "answer": "B"
  },
  {
    "id": 106,
    "question": "## Question #106\n\nA company is introducing a mobile app that helps users learn foreign languages. The app makes text more coherent by calling a large language model (LLM). The company collected a diverse dataset of text and supplemented the dataset with examples of more readable versions. The company wants the LLM output to resemble the provided examples.\n\nWhich metric should the company use to assess whether the LLM meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Value of the loss function",
      "B": "Semantic robustness",
      "C": "Recall-Oriented Understudy for Gisting Evaluation (ROUGE) score",
      "D": "Latency of the text generation "
    },
    "answer": "C"
  },
  {
    "id": 107,
    "question": "## Question #107\n\nA company notices that its foundation model (FM) generates images that are unrelated to the prompts. The company wants to modify the prompt techniques to decrease unrelated images.\n\nWhich solution meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Use zero-shot prompts.",
      "B": "Use negative prompts.",
      "C": "Use positive prompts.",
      "D": "Use ambiguous prompts. "
    },
    "answer": "B"
  },
  {
    "id": 108,
    "question": "## Question #108\n\nA company wants to use a large language model (LLM) to generate concise, feature-specific descriptions for the company’s products.\n\nWhich prompt engineering technique meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Create one prompt that covers all products. Edit the responses to make the responses more specific, concise, and tailored to each product.",
      "B": "Create prompts for each product category that highlight the key features. Include the desired output format and length for each prompt response.",
      "C": "Include a diverse range of product features in each prompt to generate creative and unique descriptions.",
      "D": "Provide detailed, product-specific prompts to ensure precise and customized descriptions. "
    },
    "answer": "B"
  },
  {
    "id": 109,
    "question": "## Question #109\n\nA company is developing an ML model to predict customer churn. The model performs well on the training dataset but does not accurately predict churn for new data.\n\nWhich solution will resolve this issue?",
    "question_type": "single_select",
    "options": {
      "A": "Decrease the regularization parameter to increase model complexity.",
      "B": "Increase the regularization parameter to decrease model complexity.",
      "C": "Add more features to the input data.",
      "D": "Train the model for more epochs. "
    },
    "answer": "B"
  },
  {
    "id": 110,
    "question": "## Question #110\n\nA company is implementing intelligent agents to provide conversational search experiences for its customers. The company needs a database service that will support storage and queries of embeddings from a generative AI model as vectors in the database.\n\nWhich AWS service will meet these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Amazon Athena",
      "B": "Amazon Aurora PostgreSQL",
      "C": "Amazon Redshift",
      "D": "Amazon EMR "
    },
    "answer": "B"
  },
  {
    "id": 111,
    "question": "## Question #111\n\nA financial institution is building an AI solution to make loan approval decisions by using a foundation model (FM). For security and audit purposes, the company needs the AI solution's decisions to be explainable.\n\nWhich factor relates to the explainability of the AI solution's decisions?",
    "question_type": "single_select",
    "options": {
      "A": "Model complexity",
      "B": "Training time",
      "C": "Number of hyperparameters",
      "D": "Deployment time "
    },
    "answer": "A"
  },
  {
    "id": 112,
    "question": "## Question #112\n\nA pharmaceutical company wants to analyze user reviews of new medications and provide a concise overview for each medication.\n\nWhich solution meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Create a time-series forecasting model to analyze the medication reviews by using Amazon Personalize.",
      "B": "Create medication review summaries by using Amazon Bedrock large language models (LLMs).",
      "C": "Create a classification model that categorizes medications into different groups by using Amazon SageMaker.",
      "D": "Create medication review summaries by using Amazon Rekognition. "
    },
    "answer": "B"
  },
  {
    "id": 113,
    "question": "## Question #113\n\nA company wants to build a lead prioritization application for its employees to contact potential customers. The application must give employees the ability to view and adjust the weights assigned to different variables in the model based on domain knowledge and expertise.\n\nWhich ML model type meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Logistic regression model",
      "B": "Deep learning model built on principal components",
      "C": "K-nearest neighbors (k-NN) model",
      "D": "Neural network "
    },
    "answer": "A"
  },
  {
    "id": 114,
    "question": "## Question #114\n\nHOTSPOT - A company wants to build an ML application.\n\nSelect and order the correct steps from the following list to develop a well-architected ML workload. Each step should be selected one time.",
    "question_type": "hotspot_dropdown",
    "options": {},
    "answer": null,
    "items": [
      {
        "prompt": "Step 1",
        "options": [
          "Deploy model",
          "Develop model",
          "Monitor model",
          "Define business goal and frame ML problem"
        ],
        "answer": "Define business goal and frame ML problem"
      },
      {
        "prompt": "Step 2",
        "options": [
          "Deploy model",
          "Develop model",
          "Monitor model",
          "Define business goal and frame ML problem"
        ],
        "answer": "Develop model"
      },
      {
        "prompt": "Step 3",
        "options": [
          "Deploy model",
          "Develop model",
          "Monitor model",
          "Define business goal and frame ML problem"
        ],
        "answer": "Deploy model"
      },
      {
        "prompt": "Step 4",
        "options": [
          "Deploy model",
          "Develop model",
          "Monitor model",
          "Define business goal and frame ML problem"
        ],
        "answer": "Monitor model"
      }
    ]
  },
  {
    "id": 115,
    "question": "## Question #115\n\nWhich strategy will determine if a foundation model (FM) effectively meets business objectives?",
    "question_type": "single_select",
    "options": {
      "A": "Evaluate the model's performance on benchmark datasets.",
      "B": "Analyze the model's architecture and hyperparameters.",
      "C": "Assess the model's alignment with specific use cases.",
      "D": "Measure the computational resources required for model deployment. "
    },
    "answer": "C"
  },
  {
    "id": 116,
    "question": "## Question #116\n\nA company needs to train an ML model to classify images of different types of animals. The company has a large dataset of labeled images and will not label more data.\n\nWhich type of learning should the company use to train the model?",
    "question_type": "single_select",
    "options": {
      "A": "Supervised learning",
      "B": "Unsupervised learning",
      "C": "Reinforcement learning",
      "D": "Active learning "
    },
    "answer": "A"
  },
  {
    "id": 117,
    "question": "## Question #117\n\nWhich phase of the ML lifecycle determines compliance and regulatory requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Feature engineering",
      "B": "Model training",
      "C": "Data collection",
      "D": "Business goal identification "
    },
    "answer": "D"
  },
  {
    "id": 118,
    "question": "## Question #118\n\nA food service company wants to develop an ML model to help decrease daily food waste and increase sales revenue. The company needs to continuously improve the model's accuracy.\n\nWhich solution meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Use Amazon SageMaker and iterate with newer data.",
      "B": "Use Amazon Personalize and iterate with historical data.",
      "C": "Use Amazon CloudWatch to analyze customer orders.",
      "D": "Use Amazon Rekognition to optimize the model. "
    },
    "answer": "A"
  },
  {
    "id": 119,
    "question": "## Question #119\n\nA company has developed an ML model to predict real estate sale prices. The company wants to deploy the model to make predictions without managing servers or infrastructure.\n\nWhich solution meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Deploy the model on an Amazon EC2 instance.",
      "B": "Deploy the model on an Amazon Elastic Kubernetes Service (Amazon EKS) cluster.",
      "C": "Deploy the model by using Amazon CloudFront with an Amazon S3 integration.",
      "D": "Deploy the model by using an Amazon SageMaker endpoint. "
    },
    "answer": "D"
  },
  {
    "id": 120,
    "question": "## Question #120\n\nA company wants to develop an AI application to help its employees check open customer claims, identify details for a specific claim, and access documents for a claim.\n\nWhich solution meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Use Agents for Amazon Bedrock with Amazon Fraud Detector to build the application.",
      "B": "Use Agents for Amazon Bedrock with Amazon Bedrock knowledge bases to build the application.",
      "C": "Use Amazon Personalize with Amazon Bedrock knowledge bases to build the application.",
      "D": "Use Amazon SageMaker to build the application by training a new ML model. "
    },
    "answer": "B"
  },
  {
    "id": 121,
    "question": "## Question #121\n\nA manufacturing company uses AI to inspect products and find any damages or defects.\n\nWhich type of AI application is the company using?",
    "question_type": "single_select",
    "options": {
      "A": "Recommendation system",
      "B": "Natural language processing (NLP)",
      "C": "Computer vision",
      "D": "Image processing "
    },
    "answer": "C"
  },
  {
    "id": 122,
    "question": "## Question #122\n\nA company wants to create an ML model to predict customer satisfaction. The company needs fully automated model tuning.\n\nWhich AWS service meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Amazon Personalize",
      "B": "Amazon SageMaker",
      "C": "Amazon Athena",
      "D": "Amazon Comprehend "
    },
    "answer": "B"
  },
  {
    "id": 123,
    "question": "## Question #123\n\nWhich technique can a company use to lower bias and toxicity in generative AI applications during the post-processing ML lifecycle?",
    "question_type": "single_select",
    "options": {
      "A": "Human-in-the-loop",
      "B": "Data augmentation",
      "C": "Feature engineering",
      "D": "Adversarial training "
    },
    "answer": "A"
  },
  {
    "id": 124,
    "question": "## Question #124\n\nA bank has fine-tuned a large language model (LLM) to expedite the loan approval process. During an external audit of the model, the company discovered that the model was approving loans at a faster pace for a specific demographic than for other demographics.\n\nHow should the bank fix this issue MOST cost-effectively?",
    "question_type": "single_select",
    "options": {
      "A": "Include more diverse training data. Fine-tune the model again by using the new data.",
      "B": "Use Retrieval Augmented Generation (RAG) with the fine-tuned model.",
      "C": "Use AWS Trusted Advisor checks to eliminate bias.",
      "D": "Pre-train a new LLM with more diverse training data. "
    },
    "answer": "A"
  },
  {
    "id": 125,
    "question": "## Question #125\n\nHOTSPOT - A company has developed a large language model (LLM) and wants to make the LLM available to multiple internal teams. The company needs to select the appropriate inference mode for each team.\n\nSelect the correct inference mode from the following list for each use case. Each inference mode should be selected one or more times.",
    "question_type": "hotspot_dropdown",
    "options": {},
    "answer": null,
    "items": [
      {
        "prompt": "The company's chatbot needs predictions from the LLM to understand users' intent with minimal latency.",
        "options": [
          "Batch transform",
          "Real-time inference"
        ],
        "answer": "Real-time inference"
      },
      {
        "prompt": "A data processing job needs to query the LLM to process gigabytes of text files on weekends.",
        "options": [
          "Batch transform",
          "Real-time inference"
        ],
        "answer": "Batch transform"
      },
      {
        "prompt": "The company's engineering team needs to create an API that can process small pieces of text content and provide low-latency predictions.",
        "options": [
          "Batch transform",
          "Real-time inference"
        ],
        "answer": "Real-time inference"
      }
    ]
  },
  {
    "id": 126,
    "question": "## Question #126\n\nA company needs to log all requests made to its Amazon Bedrock API. The company must retain the logs securely for 5 years at the lowest possible cost.\n\nWhich combination of AWS service and storage class meets these requirements? (Choose two.)",
    "question_type": "multi_select",
    "options": {
      "A": "AWS CloudTrail",
      "B": "Amazon CloudWatch",
      "C": "AWS Audit Manager",
      "D": "Amazon S3 Intelligent-Tiering",
      "E": "Amazon S3 Standard "
    },
    "answer": "AD"
  },
  {
    "id": 127,
    "question": "## Question #127\n\nAn ecommerce company wants to improve search engine recommendations by customizing the results for each user of the company’s ecommerce platform.\n\nWhich AWS service meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Amazon Personalize",
      "B": "Amazon Kendra",
      "C": "Amazon Rekognition",
      "D": "Amazon Transcribe "
    },
    "answer": "A"
  },
  {
    "id": 128,
    "question": "## Question #128\n\nA hospital is developing an AI system to assist doctors in diagnosing diseases based on patient records and medical images.\n\nTo comply with regulations, the sensitive patient data must not leave the country the data is located in.\n\nWhich data governance strategy will ensure compliance and protect patient privacy?",
    "question_type": "single_select",
    "options": {
      "A": "Data residency",
      "B": "Data quality",
      "C": "Data discoverability",
      "D": "Data enrichment "
    },
    "answer": "A"
  },
  {
    "id": 129,
    "question": "## Question #129\n\nA company needs to monitor the performance of its ML systems by using a highly scalable AWS service.\n\nWhich AWS service meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Amazon CloudWatch",
      "B": "AWS CloudTrail",
      "C": "AWS Trusted Advisor",
      "D": "AWS Config "
    },
    "answer": "A"
  },
  {
    "id": 130,
    "question": "## Question #130\n\nAn AI practitioner is developing a prompt for an Amazon Titan model. The model is hosted on Amazon Bedrock. The AI practitioner is using the model to solve numerical reasoning challenges. The AI practitioner adds the following phrase to the end of the prompt: “Ask the model to show its work by explaining its reasoning step by step.” Which prompt engineering technique is the AI practitioner using?",
    "question_type": "single_select",
    "options": {
      "A": "Chain-of-thought prompting",
      "B": "Prompt injection",
      "C": "Few-shot prompting",
      "D": "Prompt templating "
    },
    "answer": "A"
  },
  {
    "id": 131,
    "question": "## Question #131\n\nWhich AWS service makes foundation models (FMs) available to help users build and scale generative AI applications?",
    "question_type": "single_select",
    "options": {
      "A": "Amazon Q Developer",
      "B": "Amazon Bedrock",
      "C": "Amazon Kendra",
      "D": "Amazon Comprehend "
    },
    "answer": "B"
  },
  {
    "id": 132,
    "question": "## Question #132\n\nA company is building a mobile app for users who have a visual impairment. The app must be able to hear what users say and provide voice responses.\n\nWhich solution will meet these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Use a deep learning neural network to perform speech recognition.",
      "B": "Build ML models to search for patterns in numeric data.",
      "C": "Use generative AI summarization to generate human-like text.",
      "D": "Build custom models for image classification and recognition. "
    },
    "answer": "A"
  },
  {
    "id": 133,
    "question": "## Question #133\n\nA company wants to enhance response quality for a large language model (LLM) for complex problem-solving tasks. The tasks require detailed reasoning and a step-by-step explanation process.\n\nWhich prompt engineering technique meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Few-shot prompting",
      "B": "Zero-shot prompting",
      "C": "Directional stimulus prompting",
      "D": "Chain-of-thought prompting "
    },
    "answer": "D"
  },
  {
    "id": 134,
    "question": "## Question #134\n\nA company wants to keep its foundation model (FM) relevant by using the most recent data. The company wants to implement a model training strategy that includes regular updates to the FM.\n\nWhich solution meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Batch learning",
      "B": "Continuous pre-training",
      "C": "Static training",
      "D": "Latent training "
    },
    "answer": "B"
  },
  {
    "id": 135,
    "question": "## Question #135\n\nHOTSPOT - A company wants to develop ML applications to improve business operations and efficiency.\n\nSelect the correct ML paradigm from the following list for each use case. Each ML paradigm should be selected one or more times.",
    "question_type": "hotspot_dropdown",
    "options": {},
    "answer": null,
    "items": [
      {
        "prompt": "Binary classification",
        "options": [
          "Supervised learning",
          "Unsupervised learning"
        ],
        "answer": "Supervised learning"
      },
      {
        "prompt": "Multi-class classification",
        "options": [
          "Supervised learning",
          "Unsupervised learning"
        ],
        "answer": "Supervised learning"
      },
      {
        "prompt": "K-means clustering",
        "options": [
          "Supervised learning",
          "Unsupervised learning"
        ],
        "answer": "Unsupervised learning"
      },
      {
        "prompt": "Dimensionality reduction",
        "options": [
          "Supervised learning",
          "Unsupervised learning"
        ],
        "answer": "Unsupervised learning"
      }
    ]
  },
  {
    "id": 136,
    "question": "## Question #136\n\nWhich option is a characteristic of AI governance frameworks for building trust and deploying human-centered AI technologies?",
    "question_type": "single_select",
    "options": {
      "A": "Expanding initiatives across business units to create long-term business value",
      "B": "Ensuring alignment with business standards, revenue goals, and stakeholder expectations",
      "C": "Overcoming challenges to drive business transformation and growth",
      "D": "Developing policies and guidelines for data, transparency, responsible AI, and compliance "
    },
    "answer": "D"
  },
  {
    "id": 137,
    "question": "## Question #137\n\nAn ecommerce company is using a generative AI chatbot to respond to customer inquiries. The company wants to measure the financial effect of the chatbot on the company’s operations.\n\nWhich metric should the company use?",
    "question_type": "single_select",
    "options": {
      "A": "Number of customer inquiries handled",
      "B": "Cost of training AI models",
      "C": "Cost for each customer conversation",
      "D": "Average handled time (AHT) "
    },
    "answer": "C"
  },
  {
    "id": 138,
    "question": "## Question #138\n\nA company wants to find groups for its customers based on the customers’ demographics and buying patterns.\n\nWhich algorithm should the company use to meet this requirement?",
    "question_type": "single_select",
    "options": {
      "A": "K-nearest neighbors (k-NN)",
      "B": "K-means",
      "C": "Decision tree",
      "D": "Support vector machine "
    },
    "answer": "B"
  },
  {
    "id": 139,
    "question": "## Question #139\n\nA company’s large language model (LLM) is experiencing hallucinations.\n\nHow can the company decrease hallucinations?",
    "question_type": "single_select",
    "options": {
      "A": "Set up Agents for Amazon Bedrock to supervise the model training.",
      "B": "Use data pre-processing and remove any data that causes hallucinations.",
      "C": "Decrease the temperature inference parameter for the model.",
      "D": "Use a foundation model (FM) that is trained to not hallucinate. "
    },
    "answer": "C"
  },
  {
    "id": 140,
    "question": "## Question #140\n\nA company is using a large language model (LLM) on Amazon Bedrock to build a chatbot. The chatbot processes customer support requests. To resolve a request, the customer and the chatbot must interact a few times.\n\nWhich solution gives the LLM the ability to use content from previous customer messages?",
    "question_type": "single_select",
    "options": {
      "A": "Turn on model invocation logging to collect messages.",
      "B": "Add messages to the model prompt.",
      "C": "Use Amazon Personalize to save conversation history.",
      "D": "Use Provisioned Throughput for the LLM. "
    },
    "answer": "B"
  },
  {
    "id": 141,
    "question": "## Question #141\n\nA company’s employees provide product descriptions and recommendations to customers when customers call the customer service center. These recommendations are based on where the customers are located. The company wants to use foundation models (FMs) to automate this process.\n\nWhich AWS service meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Amazon Macie",
      "B": "Amazon Transcribe",
      "C": "Amazon Bedrock",
      "D": "Amazon Textract "
    },
    "answer": "C"
  },
  {
    "id": 142,
    "question": "## Question #142\n\nA company wants to upload customer service email messages to Amazon S3 to develop a business analysis application. The messages sometimes contain sensitive data. The company wants to receive an alert every time sensitive information is found.\n\nWhich solution fully automates the sensitive information detection process with the LEAST development effort?",
    "question_type": "single_select",
    "options": {
      "A": "Configure Amazon Macie to detect sensitive information in the documents that are uploaded to Amazon S3.",
      "B": "Use Amazon SageMaker endpoints to deploy a large language model (LLM) to redact sensitive data.",
      "C": "Develop multiple regex patterns to detect sensitive data. Expose the regex patterns on an Amazon SageMaker notebook.",
      "D": "Ask the customers to avoid sharing sensitive information in their email messages. "
    },
    "answer": "A"
  },
  {
    "id": 143,
    "question": "## Question #143\n\nHOTSPOT - A company is training its employees on how to structure prompts for foundation models.\n\nSelect the correct prompt engineering technique from the following list for each prompt template. Each prompt engineering technique should be selected one time.",
    "question_type": "hotspot_dropdown",
    "options": {},
    "answer": null,
    "items": [
      {
        "prompt": "Classify the following text as either sports, politics, or entertainment: [input text].",
        "options": [
          "Chain-of-thought reasoning",
          "Few-shot learning",
          "Zero-shot learning"
        ],
        "answer": "Zero-shot learning"
      },
      {
        "prompt": "A [image 1], [image 2], and [image 3] are examples of [target class]. Classify the following image as [target class].",
        "options": [
          "Chain-of-thought reasoning",
          "Few-shot learning",
          "Zero-shot learning"
        ],
        "answer": "Few-shot learning"
      },
      {
        "prompt": "[Question.] [Instructions to follow.] Think step by step and walk me through your thinking.",
        "options": [
          "Chain-of-thought reasoning",
          "Few-shot learning",
          "Zero-shot learning"
        ],
        "answer": "Chain-of-thought reasoning"
      }
    ]
  },
  {
    "id": 144,
    "question": "## Question #144\n\nWhich approach is most suitable for gauging the effectiveness of a large - scale pre - trained model (LPM) when it is applied to object detection in video surveillance?",
    "question_type": "single_select",
    "options": {
      "A": "Determine the energy consumption of the model during operation.",
      "B": "Compare the model's detection results with a well - established reference dataset in terms of precision, recall and mean average precision.",
      "C": "Analyze the number of parameters in the model's architecture.",
      "D": "Evaluate the smoothness of the video output after the model processes the surveillance footage. "
    },
    "answer": "B"
  },
  {
    "id": 145,
    "question": "## Question #145\n\nWhich option is a benefit of using Amazon SageMaker Model Cards to document AI models?",
    "question_type": "single_select",
    "options": {
      "A": "Providing a visually appealing summary of a mode’s capabilities.",
      "B": "Standardizing information about a model’s purpose, performance, and limitations.",
      "C": "Reducing the overall computational requirements of a model.",
      "D": "Physically storing models for archival purposes. "
    },
    "answer": "B"
  },
  {
    "id": 146,
    "question": "## Question #146\n\nWhat does an F1 score measure in the context of foundation model (FM) performance?",
    "question_type": "single_select",
    "options": {
      "A": "Model precision and recall",
      "B": "Model speed in generating responses",
      "C": "Financial cost of operating the model",
      "D": "Energy efficiency of the model’s computations "
    },
    "answer": "A"
  },
  {
    "id": 147,
    "question": "## Question #147\n\nA company deployed an AI/ML solution to help customer service agents respond to frequently asked questions. The questions can change over time. The company wants to give customer service agents the ability to ask questions and receive automatically generated answers to common customer questions.\n\nWhich strategy will meet these requirements MOST cost-effectively?",
    "question_type": "single_select",
    "options": {
      "A": "Fine-tune the model regularly.",
      "B": "Train the model by using context data.",
      "C": "Pre-train and benchmark the model by using context data.",
      "D": "Use Retrieval Augmented Generation (RAG) with prompt engineering techniques. "
    },
    "answer": "D"
  },
  {
    "id": 148,
    "question": "## Question #148\n\nA company built an AI-powered resume screening system. The company used a large dataset to train the model. The dataset contained resumes that were not representative of all demographics.\n\nWhich core dimension of responsible AI does this scenario present?",
    "question_type": "single_select",
    "options": {
      "A": "Fairness",
      "B": "Explainability",
      "C": "Privacy and security",
      "D": "Transparency "
    },
    "answer": "A"
  },
  {
    "id": 149,
    "question": "## Question #149\n\nA global financial company has developed an ML application to analyze stock market data and provide stock market trends.\n\nThe company wants to continuously monitor the application development phases and to ensure that company policies and industry regulations are followed.\n\nWhich AWS services will help the company assess compliance requirements? (Choose two.)",
    "question_type": "multi_select",
    "options": {
      "A": "AWS Audit Manager",
      "B": "AWS Config",
      "C": "Amazon Inspector",
      "D": "Amazon CloudWatch",
      "E": "AWS CloudTrail "
    },
    "answer": "AB"
  },
  {
    "id": 150,
    "question": "## Question #150\n\nA company wants to improve the accuracy of the responses from a generative AI application. The application uses a foundation model (FM) on Amazon Bedrock.\n\nWhich solution meets these requirements MOST cost-effectively?",
    "question_type": "single_select",
    "options": {
      "A": "Fine-tune the FM.",
      "B": "Retrain the FM.",
      "C": "Train a new FM.",
      "D": "Use prompt engineering. "
    },
    "answer": "D"
  },
  {
    "id": 151,
    "question": "## Question #151\n\nA company wants to identify harmful language in the comments section of social media posts by using an ML model. The company will not use labeled data to train the model.\n\nWhich strategy should the company use to identify harmful language?",
    "question_type": "single_select",
    "options": {
      "A": "Use Amazon Rekognition moderation.",
      "B": "Use Amazon Comprehend toxicity detection.",
      "C": "Use Amazon SageMaker built-in algorithms to train the model.",
      "D": "Use Amazon Polly to monitor comments. "
    },
    "answer": "B"
  },
  {
    "id": 152,
    "question": "## Question #152\n\nA media company wants to analyze viewer behavior and demographics to recommend personalized content. The company wants to deploy a customized ML model in its production environment. The company also wants to observe if the model quality drifts over time.\n\nWhich AWS service or feature meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Amazon Rekognition",
      "B": "Amazon SageMaker Clarify",
      "C": "Amazon Comprehend",
      "D": "Amazon SageMaker Model Monitor "
    },
    "answer": "D"
  },
  {
    "id": 153,
    "question": "## Question #153\n\nA company is deploying AI/ML models by using AWS services. The company wants to offer transparency into the models’ decision-making processes and provide explanations for the model outputs.\n\nWhich AWS service or feature meets these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Amazon SageMaker Model Cards",
      "B": "Amazon Rekognition",
      "C": "Amazon Comprehend",
      "D": "Amazon Lex "
    },
    "answer": "A"
  },
  {
    "id": 154,
    "question": "## Question #154\n\nA manufacturing company wants to create product descriptions in multiple languages.\n\nWhich AWS service will automate this task?",
    "question_type": "single_select",
    "options": {
      "A": "Amazon Translate",
      "B": "Amazon Transcribe",
      "C": "Amazon Kendra",
      "D": "Amazon Polly "
    },
    "answer": "A"
  },
  {
    "id": 155,
    "question": "## Question #155\n\nHOTSPOT - A company wants more customized responses to its generative AI models’ prompts.\n\nSelect the correct customization methodology from the following list for each use case. Each use case should be selected one time.",
    "question_type": "hotspot_dropdown",
    "items": [
      {
        "prompt": "The models must be taught a new domain-specific task",
        "options": [
          "Continued pre-training",
          "Data augmentation",
          "Model fine-tuning"
        ],
        "answer": "Model fine-tuning"
      },
      {
        "prompt": "A limited amount of labeled data is available and more data is needed",
        "options": [
          "Continued pre-training",
          "Data augmentation",
          "Model fine-tuning"
        ],
        "answer": "Data augmentation"
      },
      {
        "prompt": "Only unlabeled data is available",
        "options": [
          "Continued pre-training",
          "Data augmentation",
          "Model fine-tuning"
        ],
        "answer": "Continued pre-training"
      }
    ],
    "options": {},
    "answer": null
  },
  {
    "id": 156,
    "question": "## Question #156\n\nWhich AWS feature records details about ML instance data for governance and reporting?",
    "question_type": "single_select",
    "options": {
      "A": "Amazon SageMaker Model Cards",
      "B": "Amazon SageMaker Debugger",
      "C": "Amazon SageMaker Model Monitor",
      "D": "Amazon SageMaker JumpStart "
    },
    "answer": "A"
  },
  {
    "id": 157,
    "question": "## Question #157\n\nA financial company is using ML to help with some of the company’s tasks.\n\nWhich option is a use of generative AI models?",
    "question_type": "single_select",
    "options": {
      "A": "Summarizing customer complaints",
      "B": "Classifying customers based on product usage",
      "C": "Segmenting customers based on type of investments",
      "D": "Forecasting revenue for certain products "
    },
    "answer": "A"
  },
  {
    "id": 158,
    "question": "## Question #158\n\nA medical company wants to develop an AI application that can access structured patient records, extract relevant information, and generate concise summaries.\n\nWhich solution will meet these requirements?",
    "question_type": "single_select",
    "options": {
      "A": "Use Amazon Comprehend Medical to extract relevant medical entities and relationships. Apply rule-based logic to structure and format summaries.",
      "B": "Use Amazon Personalize to analyze patient engagement patterns. Integrate the output with a general purpose text summarization tool.",
      "C": "Use Amazon Textract to convert scanned documents into digital text. Design a keyword extraction system to generate summaries.",
      "D": "Implement Amazon Kendra to provide a searchable index for medical records. Use a template-based system to format summaries. "
    },
    "answer": "A"
  },
  {
    "id": 159,
    "question": "## Question #159\n\nA company is building an AI-powered image moderation system on AWS to ensure that user-uploaded images do not contain inappropriate content (e.g., violence, nudity).\n\nWhich AWS service is MOST suitable for directly detecting and blocking such content?",
    "question_type": "single_select",
    "options": {
      "A": "Amazon Rekognition",
      "B": "Amazon Comprehend",
      "C": "Amazon SageMaker",
      "D": "Amazon Textract "
    },
    "answer": "A"
  },
  {
    "id": 160,
    "question": "## Question #160\n\nA company is building an AI application to summarize books of varying lengths. During testing, the application fails to summarize some books.\n\nWhy does the application fail to summarize some books?",
    "question_type": "single_select",
    "options": {
      "A": "The temperature is set too high.",
      "B": "The selected model does not support fine-tuning.",
      "C": "The Top P value is too high.",
      "D": "The input tokens exceed the model’s context size. "
    },
    "answer": "D"
  },
  {
    "id": 161,
    "question": "## Question #161\n\nAn airline company wants to build a conversational AI assistant to answer customer questions about flight schedules, booking, and payments. The company wants to use large language models (LLMs) and a knowledge base to create a text-based chatbot interface.\n\nWhich solution will meet these requirements with the LEAST development effort?",
    "question_type": "single_select",
    "options": {
      "A": "Train models on Amazon SageMaker Autopilot.",
      "B": "Develop a Retrieval Augmented Generation (RAG) agent by using Amazon Bedrock.",
      "C": "Create a Python application by using Amazon Q Developer.",
      "D": "Fine-tune models on Amazon SageMaker Jumpstart. "
    },
    "answer": "B"
  },
  {
    "id": 162,
    "question": "## Question #162\n\nWhat is tokenization used for in natural language processing (NLP)?",
    "question_type": "single_select",
    "options": {
      "A": "To encrypt text data",
      "B": "To compress text files",
      "C": "To break text into smaller units for processing",
      "D": "To translate text between languages "
    },
    "answer": "C"
  },
  {
    "id": 163,
    "question": "## Question #163\n\nWhich option is a characteristic of transformer-based language models?",
    "question_type": "single_select",
    "options": {
      "A": "Transformer-based language models use convolutional layers to apply filters across an input to capture local patterns through filtered views.",
      "B": "Transformer-based language models can process only text data.",
      "C": "Transformer-based language models use self-attention mechanisms to capture contextual relationships.",
      "D": "Transformer-based language models process data sequences one element at a time in cyclic iterations. "
    },
    "answer": "C"
  },
  {
    "id": 164,
    "question": "## Question #164\n\nA financial company is using AI systems to obtain customer credit scores as part of the loan application process. The company wants to expand to a new market in a different geographic area. The company must ensure that it can operate in that geographic area.\n\nWhich compliance laws should the company review?",
    "question_type": "single_select",
    "options": {
      "A": "Local health data protection laws",
      "B": "Local payment card data protection laws",
      "C": "Local education privacy laws",
      "D": "Local algorithm accountability laws "
    },
    "answer": "D"
  },
  {
    "id": 165,
    "question": "## Question #165\n\nA company uses Amazon Bedrock for its generative AI application. The company wants to use Amazon Bedrock Guardrails to detect and filter harmful user inputs and model-generated outputs.\n\nWhich content categories can the guardrails filter? (Choose two.)",
    "question_type": "multi_select",
    "options": {
      "A": "Hate",
      "B": "Politics",
      "C": "Violence",
      "D": "Gambling",
      "E": "Religion "
    },
    "answer": "AC"
  },
  {
    "id": 166,
    "question": "## Question #166\n\nWhich scenario describes a potential risk and limitation of prompt engineering in the context of a generative AI model?",
    "question_type": "single_select",
    "options": {
      "A": "Prompt engineering does not ensure that the model always produces consistent and deterministic outputs, eliminating the need for validation.",
      "B": "Prompt engineering could expose the model to vulnerabilities such as prompt injection attacks.",
      "C": "Properly designed prompts reduce but do not eliminate the risk of data poisoning or model hijacking.",
      "D": "Prompt engineering does not ensure that the model will consistently generate highly reliable outputs when working with real-world data. "
    },
    "answer": "B"
  },
  {
    "id": 167,
    "question": "## Question #167\n\nA publishing company built a Retrieval Augmented Generation (RAG) based solution to give its users the ability to interact with published content. New content is published daily. The company wants to provide a near real-time experience to users.\n\nWhich steps in the RAG pipeline should the company implement by using offline batch processing to meet these requirements?\n\n(Choose two.)",
    "question_type": "multi_select",
    "options": {
      "A": "Generation of content embeddings",
      "B": "Generation of embeddings for user queries",
      "C": "Creation of the search index",
      "D": "Retrieval of relevant content",
      "E": "Response generation for the user "
    },
    "answer": "AC"
  },
  {
    "id": 168,
    "question": "## Question #168\n\nWhich technique breaks a complex task into smaller subtasks that are sent sequentially to a large language model (LLM)?",
    "question_type": "single_select",
    "options": {
      "A": "One-shot prompting",
      "B": "Prompt chaining",
      "C": "Tree of thoughts",
      "D": "Retrieval Augmented Generation (RAG) "
    },
    "answer": "B"
  }
]